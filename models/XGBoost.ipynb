{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5ad503b",
   "metadata": {},
   "source": [
    "Load and clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b23c368a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import time\n",
    "from pathlib import Path\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV, LeaveOneGroupOut\n",
    "\n",
    "# Set ROOT path to access other directories in project\n",
    "ROOT = Path.cwd().parent\n",
    "if str(ROOT) not in sys.path:\n",
    "    sys.path.insert(0, str(ROOT))\n",
    "\n",
    "import SnowDepth.data_loader as DL\n",
    "import SnowDepth.data_splitter as DS\n",
    "import SnowDepth.optimal_features as OF\n",
    "from SnowDepth.config import HOLDOUT_AOI\n",
    "from SnowDepth.config import SEED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb4795d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign seed\n",
    "seed = SEED\n",
    "\n",
    "# Path to TIFF files\n",
    "data_dir = ROOT/\"data\"/\"tif_files\"\n",
    "\n",
    "# Select holdout AOI\n",
    "holdout_aoi = HOLDOUT_AOI\n",
    "\n",
    "# Select max amount of features to select from FF algos\n",
    "top_k = 10\n",
    "\n",
    "# Load dataframe\n",
    "df = DL.build_df(str(data_dir), drop_invalid=True, upper_threshold=3)\n",
    "\n",
    "# Development dataframe we will use for training models\n",
    "dev_df  = df[df['aoi_name'] != holdout_aoi].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d752c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Block HSIC Lasso B = 20.\n",
      "M set to 3.\n",
      "Using Gaussian kernel for the features, Gaussian kernel for the outcomes.\n",
      "HSIC selected: ['IAFE', 'Gamma_VH_RTC', 'cos_Aspect', 'Gamma_VV_RTC', 'Beta_ratio', 'Slope', 'LIA', 'Gamma_RTC_ratio', 'Beta_VH', 'sin_Aspect']\n",
      "PCC selected: ['IAFE', 'cos_Aspect', 'Gamma_VH_RTC', 'Gamma_VV_RTC', 'Elevation', 'Beta_VH', 'Slope', 'LIA']\n",
      "MI selected): ['IAFE', 'Elevation', 'Gamma_VH_RTC', 'Gamma_VV_RTC', 'Gamma_RTC_sum', 'cos_Aspect', 'Beta_VH', 'Slope', 'Gamma_ratio']\n"
     ]
    }
   ],
   "source": [
    "# Run Feature filtering algorithms\n",
    "ff_algos = OF.optimal_feature_sets(dev_df, top_k=10, n_per_aoi=10000)\n",
    "base_cols = [\"aoi_name\", \"row\", \"col\", \"SD\"]\n",
    "\n",
    "# HSIC\n",
    "dev_df_HSIC  = dev_df[base_cols + ff_algos[\"HSIC\"]].copy()\n",
    "# PCC\n",
    "dev_df_PCC  = dev_df[base_cols + ff_algos[\"PCC\"]].copy()\n",
    "# MI\n",
    "dev_df_MI  = dev_df[base_cols + ff_algos[\"MI\"]].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd3e0e8",
   "metadata": {},
   "source": [
    "Split data for training XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ceda51c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples: 50000 across 5 AOIs\n",
      "Features used: ['IAFE', 'Gamma_VH_RTC', 'cos_Aspect', 'Gamma_VV_RTC', 'Beta_ratio', 'Slope', 'LIA', 'Gamma_RTC_ratio', 'Beta_VH', 'sin_Aspect']\n",
      "X_dev shape: (50000, 10)\n",
      "X_hold shape: (1655811, 10)\n",
      "Total samples: 50000 across 5 AOIs\n",
      "Features used: ['IAFE', 'cos_Aspect', 'Gamma_VH_RTC', 'Gamma_VV_RTC', 'Elevation', 'Beta_VH', 'Slope', 'LIA']\n",
      "X_dev shape: (50000, 8)\n",
      "X_hold shape: (1655811, 8)\n",
      "Total samples: 50000 across 5 AOIs\n",
      "Features used: ['IAFE', 'Elevation', 'Gamma_VH_RTC', 'Gamma_VV_RTC', 'Gamma_RTC_sum', 'cos_Aspect', 'Beta_VH', 'Slope', 'Gamma_ratio']\n",
      "X_dev shape: (50000, 9)\n",
      "X_hold shape: (1655811, 9)\n"
     ]
    }
   ],
   "source": [
    "# HSIC\n",
    "X_dev_HSIC, y_dev_HSIC, groups_HSIC = DS.ML_split(\n",
    "    dev_df=dev_df_HSIC,\n",
    "    pxs_per_aoi=10000\n",
    ")\n",
    "# PCC\n",
    "X_dev_PCC, y_dev_PCC, groups_PCC = DS.ML_split(\n",
    "    dev_df=dev_df_PCC,\n",
    "    pxs_per_aoi=10000\n",
    ")\n",
    "# MI\n",
    "X_dev_MI, y_dev_MI, groups_MI = DS.ML_split(\n",
    "    dev_df=dev_df_MI,\n",
    "    pxs_per_aoi=10000\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44f46901",
   "metadata": {},
   "source": [
    "Train XGBoost and tune hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "974f18b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n",
      "Results - XGBoost with HSIC feature set\n",
      "HSIC ‚Äî Best hyperparameters: {'subsample': 0.9, 'reg_lambda': 0.5, 'reg_alpha': 1, 'n_estimators': 600, 'min_child_weight': 2, 'max_depth': 10, 'max_bin': 512, 'learning_rate': 0.03, 'colsample_bytree': 0.7}\n",
      "HSIC ‚Äî Best CV RMSE: 0.5146892786026\n"
     ]
    }
   ],
   "source": [
    "param_dist = {\n",
    "    \"n_estimators\": [400, 600, 800, 1000],\n",
    "    \"learning_rate\": [0.03, 0.05, 0.07, 0.1, 0.15],\n",
    "    \"max_depth\": [4, 5, 6, 8, 10],\n",
    "    \"min_child_weight\": [1, 2, 4, 6, 8, 12, 16],\n",
    "    \"subsample\": [0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "    \"colsample_bytree\": [0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "    \"reg_lambda\": [0, 0.5, 1, 2, 5, 10],\n",
    "    \"reg_alpha\": [0, 1e-4, 1e-3, 1e-2, 0.1, 1],\n",
    "    \"max_bin\": [256, 512]\n",
    "}\n",
    "\n",
    "def run_xgb_search(tag, X, y, groups):\n",
    "    xgb = XGBRegressor(\n",
    "        objective=\"reg:squarederror\",\n",
    "        tree_method=\"hist\",\n",
    "        n_jobs=-1,\n",
    "        random_state=SEED,\n",
    "        eval_metric=\"rmse\"\n",
    "    )\n",
    "\n",
    "    logo = LeaveOneGroupOut()\n",
    "    search = RandomizedSearchCV(\n",
    "        estimator=xgb,\n",
    "        param_distributions=param_dist,\n",
    "        n_iter=30,\n",
    "        cv=logo,\n",
    "        scoring=\"neg_root_mean_squared_error\",\n",
    "        n_jobs=-1,\n",
    "        verbose=2,\n",
    "        random_state=SEED\n",
    "    )\n",
    "\n",
    "    start = time.time()\n",
    "    search.fit(X, y, groups=groups)\n",
    "    end = time.time()\n",
    "    elapsed = (end - start) / 60.0 \n",
    "\n",
    "    best_rmse = -search.best_score_\n",
    "    best_params = search.best_params_\n",
    "\n",
    "    print(f\"\\nResults - XGBoost with {tag} feature set\")\n",
    "    print(f\"Best hyperparameters: {best_params}\")\n",
    "    print(f\"Best CV RMSE: {best_rmse:.4f}\")\n",
    "    print(f\"Training time: {elapsed:.2f} minutes\")\n",
    "\n",
    "    return tag, best_rmse, best_params, elapsed\n",
    "\n",
    "\n",
    "# Run across feature sets\n",
    "xgb_results = {}\n",
    "timings = {}\n",
    "\n",
    "for tag, X, y, g in [\n",
    "    (\"HSIC\", X_dev_HSIC, y_dev_HSIC, groups_HSIC),\n",
    "    (\"PCC\",  X_dev_PCC,  y_dev_PCC,  groups_PCC),\n",
    "    (\"MI\",   X_dev_MI,   y_dev_MI,   groups_MI),\n",
    "]:\n",
    "    tag, rmse, params, time_min = run_xgb_search(tag, X, y, g, seed)\n",
    "    xgb_results[tag] = (rmse, params)\n",
    "    timings[tag] = time_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "396c3c59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n",
      "Results - XGBoost with PCC feature set\n",
      "PCC ‚Äî Best hyperparameters: {'subsample': 1.0, 'reg_lambda': 10, 'reg_alpha': 1, 'n_estimators': 1000, 'min_child_weight': 2, 'max_depth': 6, 'max_bin': 256, 'learning_rate': 0.1, 'colsample_bytree': 0.6}\n",
      "PCC ‚Äî Best CV RMSE: 0.5190581262111664\n"
     ]
    }
   ],
   "source": [
    "# Print leaderboard\n",
    "print(\"\\nCross-validation RMSE results (XGBoost):\")\n",
    "for name, (rmse, params) in xgb_results.items():\n",
    "    print(f\"\\n{name} ‚Äî CV RMSE: {rmse:.4f}\")\n",
    "    print(f\"{name} ‚Äî Best hyperparameters: {params}\")\n",
    "    print(f\"{name} ‚Äî Training time: {timings[name]:.2f} minutes\")\n",
    "\n",
    "# Find best model\n",
    "best_xgb_method = min(xgb_results, key=lambda k: xgb_results[k][0])\n",
    "best_xgb_rmse, best_xgb_params = xgb_results[best_xgb_method]\n",
    "\n",
    "print(f\"\\nüèÜ Best feature set with XGBoost: {best_xgb_method} \"\n",
    "      f\"(CV RMSE = {best_xgb_rmse:.4f}, time = {timings[best_xgb_method]:.2f} min)\")\n",
    "print(f\"Best XGB hyperparameters: {best_xgb_params}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
