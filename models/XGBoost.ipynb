{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5ad503b",
   "metadata": {},
   "source": [
    "Load and clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b23c368a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import time\n",
    "from pathlib import Path\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV, LeaveOneGroupOut\n",
    "\n",
    "# Set ROOT path to access other directories in project\n",
    "ROOT = Path.cwd().parent\n",
    "if str(ROOT) not in sys.path:\n",
    "    sys.path.insert(0, str(ROOT))\n",
    "\n",
    "import SnowDepth.data_loader as DL\n",
    "import SnowDepth.data_splitter as DS\n",
    "import SnowDepth.optimal_features as OF\n",
    "from SnowDepth.config import HOLDOUT_AOI\n",
    "from SnowDepth.config import SEED\n",
    "from SnowDepth.config import FEATURE_NAMES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb4795d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to TIFF files\n",
    "data_dir = ROOT/\"data\"/\"tif_files\"\n",
    "\n",
    "# Select holdout AOI\n",
    "holdout_aoi = HOLDOUT_AOI\n",
    "\n",
    "# Select max amount of features to select from FF algos\n",
    "top_k = 10\n",
    "\n",
    "# Load dataframe\n",
    "df = DL.build_df(str(data_dir), drop_invalid=True, upper_threshold=3)\n",
    "\n",
    "# Development dataframe we will use for training models\n",
    "dev_df  = df[df['aoi_name'] != holdout_aoi].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d752c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Block HSIC Lasso B = 20.\n",
      "M set to 3.\n",
      "Using Gaussian kernel for the features, Gaussian kernel for the outcomes.\n",
      "HSIC selected: ['Veg_height', 'IAFE', 'cos_Aspect', 'Gamma_VH_RTC', 'Gamma_VV_RTC', 'Sigma_ratio', 'Beta_VH', 'Gamma_RTC_ratio', 'Gamma_ratio', 'Slope']\n",
      "PCC selected: ['Veg_height', 'IAFE', 'cos_Aspect', 'Gamma_VH_RTC', 'sin_Aspect', 'Gamma_RTC_ratio', 'Beta_VH']\n",
      "MI selected): ['IAFE', 'Elevation', 'Veg_height', 'cos_Aspect', 'Gamma_RTC_sum', 'Gamma_VH_RTC', 'Gamma_VV_RTC', 'Slope', 'Gamma_ratio']\n"
     ]
    }
   ],
   "source": [
    "# Run Feature filtering algorithms\n",
    "ff_algos = OF.optimal_feature_sets(dev_df, top_k=10, n_per_aoi=10000)\n",
    "base_cols = [\"aoi_name\", \"row\", \"col\", \"SD\"]\n",
    "\n",
    "# HSIC\n",
    "dev_df_HSIC  = dev_df[base_cols + ff_algos[\"HSIC\"]].copy()\n",
    "# PCC\n",
    "dev_df_PCC  = dev_df[base_cols + ff_algos[\"PCC\"]].copy()\n",
    "# MI\n",
    "dev_df_MI  = dev_df[base_cols + ff_algos[\"MI\"]].copy()\n",
    "# ALL features (for Ablation study)\n",
    "dev_df_ALL  = dev_df[base_cols + FEATURE_NAMES].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd3e0e8",
   "metadata": {},
   "source": [
    "Split data for training XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ceda51c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples: 50000 across 5 AOIs\n",
      "Features used: ['Veg_height', 'IAFE', 'cos_Aspect', 'Gamma_VH_RTC', 'Gamma_VV_RTC', 'Sigma_ratio', 'Beta_VH', 'Gamma_RTC_ratio', 'Gamma_ratio', 'Slope']\n",
      "X_dev shape: (50000, 10)\n",
      "Total samples: 50000 across 5 AOIs\n",
      "Features used: ['Veg_height', 'IAFE', 'cos_Aspect', 'Gamma_VH_RTC', 'sin_Aspect', 'Gamma_RTC_ratio', 'Beta_VH']\n",
      "X_dev shape: (50000, 7)\n",
      "Total samples: 50000 across 5 AOIs\n",
      "Features used: ['IAFE', 'Elevation', 'Veg_height', 'cos_Aspect', 'Gamma_RTC_sum', 'Gamma_VH_RTC', 'Gamma_VV_RTC', 'Slope', 'Gamma_ratio']\n",
      "X_dev shape: (50000, 9)\n"
     ]
    }
   ],
   "source": [
    "# HSIC\n",
    "X_dev_HSIC, y_dev_HSIC, groups_HSIC = DS.ML_split(\n",
    "    dev_df=dev_df_HSIC,\n",
    "    pxs_per_aoi=10000\n",
    ")\n",
    "# PCC\n",
    "X_dev_PCC, y_dev_PCC, groups_PCC = DS.ML_split(\n",
    "    dev_df=dev_df_PCC,\n",
    "    pxs_per_aoi=10000\n",
    ")\n",
    "# MI\n",
    "X_dev_MI, y_dev_MI, groups_MI = DS.ML_split(\n",
    "    dev_df=dev_df_MI,\n",
    "    pxs_per_aoi=10000\n",
    ")\n",
    "# ALL\n",
    "X_dev_ALL, y_dev_ALL, groups_ALL = DS.ML_split(\n",
    "    dev_df=dev_df_ALL,\n",
    "    pxs_per_aoi=10000\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44f46901",
   "metadata": {},
   "source": [
    "Train XGBoost and tune hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "974f18b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n",
      "\n",
      "Results - XGBoost with HSIC feature set\n",
      "Best hyperparameters: {'subsample': 1.0, 'reg_lambda': 0, 'reg_alpha': 0.01, 'n_estimators': 600, 'min_child_weight': 4, 'max_depth': 4, 'max_bin': 512, 'learning_rate': 0.03, 'colsample_bytree': 0.9}\n",
      "Best CV RMSE: 0.4798\n",
      "Training time: 2.99 minutes\n",
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n",
      "\n",
      "Results - XGBoost with PCC feature set\n",
      "Best hyperparameters: {'subsample': 0.8, 'reg_lambda': 1, 'reg_alpha': 0.01, 'n_estimators': 800, 'min_child_weight': 1, 'max_depth': 4, 'max_bin': 256, 'learning_rate': 0.07, 'colsample_bytree': 0.9}\n",
      "Best CV RMSE: 0.4874\n",
      "Training time: 2.15 minutes\n",
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n",
      "\n",
      "Results - XGBoost with MI feature set\n",
      "Best hyperparameters: {'subsample': 0.6, 'reg_lambda': 2, 'reg_alpha': 0.001, 'n_estimators': 1000, 'min_child_weight': 8, 'max_depth': 10, 'max_bin': 512, 'learning_rate': 0.05, 'colsample_bytree': 0.6}\n",
      "Best CV RMSE: 0.4066\n",
      "Training time: 2.67 minutes\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV, LeaveOneGroupOut, cross_validate\n",
    "from xgboost import XGBRegressor\n",
    "import numpy as np, time\n",
    "\n",
    "param_dist = {\n",
    "    \"n_estimators\":      [400, 600, 800, 1000],\n",
    "    \"learning_rate\":     [0.03, 0.05, 0.07, 0.1, 0.15],\n",
    "    \"max_depth\":         [4, 5, 6, 8, 10],\n",
    "    \"min_child_weight\":  [1, 2, 4, 6, 8, 12, 16],\n",
    "    \"subsample\":         [0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "    \"colsample_bytree\":  [0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "    \"reg_lambda\":        [0, 0.5, 1, 2, 5, 10],\n",
    "    \"reg_alpha\":         [0, 1e-4, 1e-3, 1e-2, 0.1, 1],\n",
    "    \"max_bin\":           [256, 512],\n",
    "}\n",
    "\n",
    "def run_xgb_search(tag, X, y, groups, n_iter=30, seed=SEED):\n",
    "    xgb = XGBRegressor(\n",
    "        objective=\"reg:squarederror\",\n",
    "        tree_method=\"hist\",\n",
    "        n_jobs=-1,\n",
    "        random_state=seed,\n",
    "        eval_metric=\"rmse\", \n",
    "    )\n",
    "\n",
    "    logo = LeaveOneGroupOut()\n",
    "    search = RandomizedSearchCV(\n",
    "        estimator=xgb,\n",
    "        param_distributions=param_dist,\n",
    "        n_iter=n_iter,\n",
    "        cv=logo,\n",
    "        scoring=\"neg_root_mean_squared_error\", \n",
    "        n_jobs=-1,\n",
    "        verbose=2,\n",
    "        random_state=seed,\n",
    "        refit=True\n",
    "    )\n",
    "\n",
    "    t0 = time.time()\n",
    "    search.fit(X, y, groups=groups)\n",
    "    elapsed = (time.time() - t0) / 60.0\n",
    "\n",
    "    best_rmse = -search.best_score_\n",
    "    best_params = search.best_params_\n",
    "\n",
    "    # Re-evaluate with cross_validate to report both RMSE and MAE\n",
    "    best_xgb = XGBRegressor(**best_params, objective=\"reg:squarederror\",\n",
    "                            tree_method=\"hist\", n_jobs=-1, random_state=seed, eval_metric=\"rmse\")\n",
    "    scores = cross_validate(\n",
    "        best_xgb, X, y, groups=groups, cv=logo, n_jobs=-1, verbose=0,\n",
    "        scoring={\"rmse\": \"neg_root_mean_squared_error\", \"mae\": \"neg_mean_absolute_error\"}\n",
    "    )\n",
    "    cv_rmse = -np.mean(scores[\"test_rmse\"])\n",
    "    cv_mae  = -np.mean(scores[\"test_mae\"])\n",
    "\n",
    "    print(f\"\\nResults - XGBoost with {tag} feature set\")\n",
    "    print(f\"Best hyperparameters: {best_params}\")\n",
    "    print(f\"Best CV RMSE (search score): {best_rmse:.4f}\")\n",
    "    print(f\"Cross-validated (re-fit) RMSE: {cv_rmse:.4f} | MAE: {cv_mae:.4f}\")\n",
    "    print(f\"Training time: {elapsed:.2f} minutes\")\n",
    "\n",
    "    return tag, cv_rmse, cv_mae, best_params, elapsed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "396c3c59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n",
      "Results - XGBoost with PCC feature set\n",
      "PCC — Best hyperparameters: {'subsample': 1.0, 'reg_lambda': 10, 'reg_alpha': 1, 'n_estimators': 1000, 'min_child_weight': 2, 'max_depth': 6, 'max_bin': 256, 'learning_rate': 0.1, 'colsample_bytree': 0.6}\n",
      "PCC — Best CV RMSE: 0.5190581262111664\n"
     ]
    }
   ],
   "source": [
    "xgb_results = {} \n",
    "xgb_timings = {}\n",
    "\n",
    "runs = [\n",
    "    (\"HSIC\", X_dev_HSIC, y_dev_HSIC, groups_HSIC),\n",
    "    (\"PCC\",  X_dev_PCC,  y_dev_PCC,  groups_PCC),\n",
    "    (\"MI\",   X_dev_MI,   y_dev_MI,   groups_MI),\n",
    "    (\"ALL\",  X_dev_ALL,  y_dev_ALL,  groups_ALL),  \n",
    "]\n",
    "\n",
    "for tag, X, y, g in runs:\n",
    "    tag, rmse, mae, params, tmin = run_xgb_search(tag, X, y, g)\n",
    "    xgb_results[tag] = (rmse, mae, params)\n",
    "    xgb_timings[tag] = tmin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbf101a3",
   "metadata": {},
   "source": [
    "print(\"\\nCross-validation results (XGBoost):\")\n",
    "for name, (rmse, mae, params) in xgb_results.items():\n",
    "    print(f\"\\n{name} — CV RMSE: {rmse:.4f} | CV MAE: {mae:.4f}\")\n",
    "    print(f\"{name} — Best hyperparameters: {params}\")\n",
    "    print(f\"{name} — Training time: {xgb_timings[name]:.2f} minutes\")\n",
    "\n",
    "best_xgb_method = min(xgb_results, key=lambda k: xgb_results[k][0])\n",
    "best_xgb_rmse, best_xgb_mae, best_xgb_params = xgb_results[best_xgb_method]\n",
    "\n",
    "print(f\"\\n🏆 Best feature set with XGBoost: {best_xgb_method} \"\n",
    "      f\"(CV RMSE = {best_xgb_rmse:.4f}, CV MAE = {best_xgb_mae:.4f}, \"\n",
    "      f\"time = {xgb_timings[best_xgb_method]:.2f} min)\")\n",
    "print(f\"Best XGB hyperparameters: {best_xgb_params}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
