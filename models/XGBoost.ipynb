{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5ad503b",
   "metadata": {},
   "source": [
    "Load and clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b23c368a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV, LeaveOneGroupOut\n",
    "\n",
    "# Set ROOT path to access other directories in project\n",
    "ROOT = Path.cwd().parent\n",
    "if str(ROOT) not in sys.path:\n",
    "    sys.path.insert(0, str(ROOT))\n",
    "\n",
    "import SnowDepth.data_loader as DL\n",
    "import SnowDepth.data_splitter as DS\n",
    "import SnowDepth.optimal_features as OF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cb4795d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign seed\n",
    "seed = 18\n",
    "\n",
    "# Path to TIFF files\n",
    "data_dir = ROOT/\"data\"/\"tif_files\"\n",
    "\n",
    "# Select holdout AOI\n",
    "holdout_aoi=\"ID_BS\"\n",
    "\n",
    "# Select amount of features to select from FF algos\n",
    "top_k = 10\n",
    "\n",
    "# Load dataframe\n",
    "df = DL.build_df(str(data_dir), drop_invalid=True, upper_threshold=3)\n",
    "\n",
    "dev_df  = df[df['aoi_name'] != holdout_aoi].copy()\n",
    "hold_df = df[df['aoi_name'] == holdout_aoi].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "05d752c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Block HSIC Lasso B = 20.\n",
      "M set to 3.\n",
      "Using Gaussian kernel for the features, Gaussian kernel for the outcomes.\n",
      "HSIC selected: ['IAFE', 'Gamma_VH_RTC', 'cos_Aspect', 'Gamma_VV_RTC', 'Beta_ratio', 'Slope', 'LIA', 'Gamma_RTC_ratio', 'Beta_VH', 'sin_Aspect']\n",
      "PCC selected: ['IAFE', 'cos_Aspect', 'Gamma_VH_RTC', 'Gamma_VV_RTC', 'Elevation', 'Beta_VH', 'Slope', 'LIA']\n",
      "MI selected): ['IAFE', 'Elevation', 'Gamma_VH_RTC', 'Gamma_VV_RTC', 'Gamma_RTC_sum', 'cos_Aspect', 'Beta_VH', 'Slope', 'Gamma_ratio']\n"
     ]
    }
   ],
   "source": [
    "ff_algos = OF.optimal_feature_sets(dev_df, top_k=10, n_per_aoi=10000)\n",
    "\n",
    "base_cols = [\"aoi_name\", \"row\", \"col\", \"SD\"]\n",
    "\n",
    "# HSIC\n",
    "dev_df_HSIC  = dev_df[base_cols + ff_algos[\"HSIC\"]].copy()\n",
    "hold_df_HSIC = hold_df[base_cols + ff_algos[\"HSIC\"]].copy()\n",
    "\n",
    "# PCC\n",
    "dev_df_PCC  = dev_df[base_cols + ff_algos[\"PCC\"]].copy()\n",
    "hold_df_PCC = hold_df[base_cols + ff_algos[\"PCC\"]].copy()\n",
    "\n",
    "# MI\n",
    "dev_df_MI  = dev_df[base_cols + ff_algos[\"MI\"]].copy()\n",
    "hold_df_MI = hold_df[base_cols + ff_algos[\"MI\"]].copy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd3e0e8",
   "metadata": {},
   "source": [
    "Split data for training XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7ceda51c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples: 50000 across 5 AOIs\n",
      "Features used: ['IAFE', 'Gamma_VH_RTC', 'cos_Aspect', 'Gamma_VV_RTC', 'Beta_ratio', 'Slope', 'LIA', 'Gamma_RTC_ratio', 'Beta_VH', 'sin_Aspect']\n",
      "X_dev shape: (50000, 10)\n",
      "X_hold shape: (1655811, 10)\n",
      "Total samples: 50000 across 5 AOIs\n",
      "Features used: ['IAFE', 'cos_Aspect', 'Gamma_VH_RTC', 'Gamma_VV_RTC', 'Elevation', 'Beta_VH', 'Slope', 'LIA']\n",
      "X_dev shape: (50000, 8)\n",
      "X_hold shape: (1655811, 8)\n",
      "Total samples: 50000 across 5 AOIs\n",
      "Features used: ['IAFE', 'Elevation', 'Gamma_VH_RTC', 'Gamma_VV_RTC', 'Gamma_RTC_sum', 'cos_Aspect', 'Beta_VH', 'Slope', 'Gamma_ratio']\n",
      "X_dev shape: (50000, 9)\n",
      "X_hold shape: (1655811, 9)\n"
     ]
    }
   ],
   "source": [
    "# HSIC\n",
    "X_dev_HSIC, y_dev_HSIC, groups_HSIC, X_hold_HSIC, y_hold_HSIC = DS.ML_split(\n",
    "    dev_df=dev_df_HSIC,\n",
    "    hold_df=hold_df_HSIC,\n",
    "    seed=seed,\n",
    "    pxs_per_aoi=10000\n",
    ")\n",
    "\n",
    "# PCC\n",
    "X_dev_PCC, y_dev_PCC, groups_PCC, X_hold_PCC, y_hold_PCC = DS.ML_split(\n",
    "    dev_df=dev_df_PCC,\n",
    "    hold_df=hold_df_PCC,\n",
    "    seed=seed,\n",
    "    pxs_per_aoi=10000\n",
    ")\n",
    "\n",
    "# MI\n",
    "X_dev_MI, y_dev_MI, groups_MI, X_hold_MI, y_hold_MI = DS.ML_split(\n",
    "    dev_df=dev_df_MI,\n",
    "    hold_df=hold_df_MI,\n",
    "    seed=seed,\n",
    "    pxs_per_aoi=10000\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44f46901",
   "metadata": {},
   "source": [
    "Train XGBoost and tune hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "974f18b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n",
      "Results - XGBoost with HSIC feature set\n",
      "HSIC — Best hyperparameters: {'subsample': 0.9, 'reg_lambda': 0.5, 'reg_alpha': 1, 'n_estimators': 600, 'min_child_weight': 2, 'max_depth': 10, 'max_bin': 512, 'learning_rate': 0.03, 'colsample_bytree': 0.7}\n",
      "HSIC — Best CV RMSE: 0.5146892786026\n"
     ]
    }
   ],
   "source": [
    "xgb = XGBRegressor(\n",
    "    objective=\"reg:squarederror\",\n",
    "    tree_method=\"hist\",  \n",
    "    n_jobs=1,             \n",
    "    random_state=seed,\n",
    "    eval_metric=\"rmse\"\n",
    ")\n",
    "\n",
    "# Hyperparameters\n",
    "param_dist = {\n",
    "    \"n_estimators\": [400, 600, 800, 1000],\n",
    "    \"learning_rate\": [0.03, 0.05, 0.07, 0.1, 0.15],\n",
    "    \"max_depth\": [4, 5, 6, 8, 10],\n",
    "    \"min_child_weight\": [1, 2, 4, 6, 8, 12, 16],\n",
    "    \"subsample\": [0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "    \"colsample_bytree\": [0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "    \"reg_lambda\": [0, 0.5, 1, 2, 5, 10],\n",
    "    \"reg_alpha\": [0, 1e-4, 1e-3, 1e-2, 0.1, 1],\n",
    "    \"max_bin\": [256, 512]\n",
    "}\n",
    "\n",
    "logo = LeaveOneGroupOut()\n",
    "\n",
    "HSIC_search = RandomizedSearchCV(\n",
    "    estimator=xgb,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=30, \n",
    "    cv=logo,\n",
    "    scoring=\"neg_root_mean_squared_error\",\n",
    "    n_jobs=-1,\n",
    "    verbose=2,\n",
    "    random_state=seed\n",
    ")\n",
    "\n",
    "# Fit\n",
    "HSIC_search.fit(X_dev_HSIC, y_dev_HSIC, groups=groups_HSIC)\n",
    "\n",
    "# CV results\n",
    "print(\"Results - XGBoost with HSIC feature set\")\n",
    "print(\"HSIC — Best hyperparameters:\", HSIC_search.best_params_)\n",
    "print(\"HSIC — Best CV RMSE:\", -HSIC_search.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e863d840",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n",
      "Results - XGBoost with PCC feature set\n",
      "PCC — Best hyperparameters: {'subsample': 1.0, 'reg_lambda': 10, 'reg_alpha': 1, 'n_estimators': 1000, 'min_child_weight': 2, 'max_depth': 6, 'max_bin': 256, 'learning_rate': 0.1, 'colsample_bytree': 0.6}\n",
      "PCC — Best CV RMSE: 0.5190581262111664\n"
     ]
    }
   ],
   "source": [
    "# XGBoost with PCC feature set\n",
    "\n",
    "xgb = XGBRegressor(\n",
    "    objective=\"reg:squarederror\",\n",
    "    tree_method=\"hist\",\n",
    "    n_jobs=1,\n",
    "    random_state=seed,\n",
    "    eval_metric=\"rmse\"\n",
    ")\n",
    "\n",
    "param_dist = {\n",
    "    \"n_estimators\": [400, 600, 800, 1000],\n",
    "    \"learning_rate\": [0.03, 0.05, 0.07, 0.1, 0.15],\n",
    "    \"max_depth\": [4, 5, 6, 8, 10],\n",
    "    \"min_child_weight\": [1, 2, 4, 6, 8, 12, 16],\n",
    "    \"subsample\": [0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "    \"colsample_bytree\": [0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "    \"reg_lambda\": [0, 0.5, 1, 2, 5, 10],\n",
    "    \"reg_alpha\": [0, 1e-4, 1e-3, 1e-2, 0.1, 1],\n",
    "    \"max_bin\": [256, 512]\n",
    "}\n",
    "\n",
    "logo = LeaveOneGroupOut()\n",
    "\n",
    "PCC_search = RandomizedSearchCV(\n",
    "    estimator=xgb,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=30,\n",
    "    cv=logo,\n",
    "    scoring=\"neg_root_mean_squared_error\",\n",
    "    n_jobs=-1,\n",
    "    verbose=2,\n",
    "    random_state=seed\n",
    ")\n",
    "\n",
    "# Fit\n",
    "PCC_search.fit(X_dev_PCC, y_dev_PCC, groups=groups_PCC)\n",
    "\n",
    "# CV results\n",
    "print(\"Results - XGBoost with PCC feature set\")\n",
    "print(\"PCC — Best hyperparameters:\", PCC_search.best_params_)\n",
    "print(\"PCC — Best CV RMSE:\", -PCC_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "396c3c59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n",
      "Results - XGBoost with PCC feature set\n",
      "PCC — Best hyperparameters: {'subsample': 1.0, 'reg_lambda': 10, 'reg_alpha': 1, 'n_estimators': 1000, 'min_child_weight': 2, 'max_depth': 6, 'max_bin': 256, 'learning_rate': 0.1, 'colsample_bytree': 0.6}\n",
      "PCC — Best CV RMSE: 0.5190581262111664\n"
     ]
    }
   ],
   "source": [
    "# XGBoost with PCC feature set\n",
    "\n",
    "xgb = XGBRegressor(\n",
    "    objective=\"reg:squarederror\",\n",
    "    tree_method=\"hist\",\n",
    "    n_jobs=1,\n",
    "    random_state=seed,\n",
    "    eval_metric=\"rmse\"\n",
    ")\n",
    "\n",
    "param_dist = {\n",
    "    \"n_estimators\": [400, 600, 800, 1000],\n",
    "    \"learning_rate\": [0.03, 0.05, 0.07, 0.1, 0.15],\n",
    "    \"max_depth\": [4, 5, 6, 8, 10],\n",
    "    \"min_child_weight\": [1, 2, 4, 6, 8, 12, 16],\n",
    "    \"subsample\": [0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "    \"colsample_bytree\": [0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "    \"reg_lambda\": [0, 0.5, 1, 2, 5, 10],\n",
    "    \"reg_alpha\": [0, 1e-4, 1e-3, 1e-2, 0.1, 1],\n",
    "    \"max_bin\": [256, 512]\n",
    "}\n",
    "\n",
    "logo = LeaveOneGroupOut()\n",
    "\n",
    "PCC_search = RandomizedSearchCV(\n",
    "    estimator=xgb,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=30,\n",
    "    cv=logo,\n",
    "    scoring=\"neg_root_mean_squared_error\",\n",
    "    n_jobs=-1,\n",
    "    verbose=2,\n",
    "    random_state=seed\n",
    ")\n",
    "\n",
    "# Fit\n",
    "PCC_search.fit(X_dev_PCC, y_dev_PCC, groups=groups_PCC)\n",
    "\n",
    "# CV results\n",
    "print(\"Results - XGBoost with PCC feature set\")\n",
    "print(\"PCC — Best hyperparameters:\", PCC_search.best_params_)\n",
    "print(\"PCC — Best CV RMSE:\", -PCC_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed538aa6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'XGBRegressor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# XGBoost with MI feature set\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m xgb \u001b[38;5;241m=\u001b[39m \u001b[43mXGBRegressor\u001b[49m(\n\u001b[0;32m      4\u001b[0m     objective\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreg:squarederror\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      5\u001b[0m     tree_method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhist\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      6\u001b[0m     n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m      7\u001b[0m     random_state\u001b[38;5;241m=\u001b[39mseed,\n\u001b[0;32m      8\u001b[0m     eval_metric\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrmse\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      9\u001b[0m )\n\u001b[0;32m     11\u001b[0m param_dist \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_estimators\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;241m400\u001b[39m, \u001b[38;5;241m600\u001b[39m, \u001b[38;5;241m800\u001b[39m, \u001b[38;5;241m1000\u001b[39m],\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlearning_rate\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;241m0.03\u001b[39m, \u001b[38;5;241m0.05\u001b[39m, \u001b[38;5;241m0.07\u001b[39m, \u001b[38;5;241m0.1\u001b[39m, \u001b[38;5;241m0.15\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_bin\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;241m256\u001b[39m, \u001b[38;5;241m512\u001b[39m]\n\u001b[0;32m     21\u001b[0m }\n\u001b[0;32m     23\u001b[0m logo \u001b[38;5;241m=\u001b[39m LeaveOneGroupOut()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'XGBRegressor' is not defined"
     ]
    }
   ],
   "source": [
    "# XGBoost with MI feature set\n",
    "\n",
    "xgb = XGBRegressor(\n",
    "    objective=\"reg:squarederror\",\n",
    "    tree_method=\"hist\",\n",
    "    n_jobs=1,\n",
    "    random_state=seed,\n",
    "    eval_metric=\"rmse\"\n",
    ")\n",
    "\n",
    "param_dist = {\n",
    "    \"n_estimators\": [400, 600, 800, 1000],\n",
    "    \"learning_rate\": [0.03, 0.05, 0.07, 0.1, 0.15],\n",
    "    \"max_depth\": [4, 5, 6, 8, 10],\n",
    "    \"min_child_weight\": [1, 2, 4, 6, 8, 12, 16],\n",
    "    \"subsample\": [0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "    \"colsample_bytree\": [0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "    \"reg_lambda\": [0, 0.5, 1, 2, 5, 10],\n",
    "    \"reg_alpha\": [0, 1e-4, 1e-3, 1e-2, 0.1, 1],\n",
    "    \"max_bin\": [256, 512]\n",
    "}\n",
    "\n",
    "logo = LeaveOneGroupOut()\n",
    "\n",
    "MI_search = RandomizedSearchCV(\n",
    "    estimator=xgb,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=30,\n",
    "    cv=logo,\n",
    "    scoring=\"neg_root_mean_squared_error\",\n",
    "    n_jobs=-1,\n",
    "    verbose=2,\n",
    "    random_state=seed\n",
    ")\n",
    "\n",
    "# Fit\n",
    "MI_search.fit(X_dev_MI, y_dev_MI, groups=groups_MI)\n",
    "\n",
    "# CV results\n",
    "print(\"Results - XGBoost with MI feature set\")\n",
    "print(\"MI — Best hyperparameters:\", MI_search.best_params_)\n",
    "print(\"MI — Best CV RMSE:\", -MI_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f8df158",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print best XGBoost model and feature set\n",
    "\n",
    "xgb_results = {\n",
    "    \"HSIC\": (-HSIC_search.best_score_, HSIC_search.best_params_),\n",
    "    \"PCC\":  (-PCC_search.best_score_,  PCC_search.best_params_),\n",
    "    \"MI\":   (-MI_search.best_score_,   MI_search.best_params_),\n",
    "}\n",
    "\n",
    "print(\"\\nCross-validation RMSE results (XGBoost):\")\n",
    "for name, (rmse, params) in xgb_results.items():\n",
    "    print(f\"\\n{name} — CV RMSE: {rmse:.4f}\")\n",
    "    print(f\"{name} — Best hyperparameters: {params}\")\n",
    "\n",
    "# Find the winner\n",
    "best_xgb_method = min(xgb_results, key=lambda k: xgb_results[k][0])\n",
    "best_xgb_rmse, best_xgb_params = xgb_results[best_xgb_method]\n",
    "\n",
    "print(f\"\\n🏆 Best feature set with XGBoost: {best_xgb_method} \"\n",
    "      f\"(CV RMSE = {best_xgb_rmse:.4f})\")\n",
    "print(f\"Best XGB hyperparameters: {best_xgb_params}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
